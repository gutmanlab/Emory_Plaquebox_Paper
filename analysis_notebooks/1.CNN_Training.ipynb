{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) CNN Training\n",
    "\n",
    "Training fresh CNN model using provided training and validation images. Information of CNN model architecture and training and validation images can be found at: https://github.com/keiserlab/plaquebox-paper.\n",
    "\n",
    "You can train a new model all together, just specify the locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "import torch\n",
    "torch.manual_seed(123456789)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from os.path import join as oj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "DATA_DIR = '/mnt/Data/'\n",
    "BATCH_SIZE = 48\n",
    "NUM_WORKERS = 12\n",
    "SAVE_DIR = '../models/'\n",
    "SAVE_NAME = 'new_model_params.pkl'\n",
    "CSV_PATH = {\n",
    "    'train': '../CSVs/train_oversampled.csv',\n",
    "    'dev': '../CSVs/dev_oversampled.csv'\n",
    "}\n",
    "IMAGE_CLASSES = ['cored','diffuse','CAA'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training\n",
    "DATA_DIR = oj(DATA_DIR, 'Tiles/train_and_val/')\n",
    "\n",
    "class MultilabelDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data_info = pd.read_csv(csv_path)\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        c=torch.Tensor(self.data_info.loc[:,'cored'])\n",
    "        d=torch.Tensor(self.data_info.loc[:,'diffuse'])\n",
    "        a=torch.Tensor(self.data_info.loc[:,'CAA'])\n",
    "        c=c.view(c.shape[0],1)\n",
    "        d=d.view(d.shape[0],1)\n",
    "        a=a.view(a.shape[0],1)\n",
    "        self.raw_labels = torch.cat([c,d,a], dim=1)\n",
    "        self.labels = (torch.cat([c,d,a], dim=1)>0.99).type(torch.FloatTensor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.labels[index]\n",
    "        raw_label = self.raw_labels[index]\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = str(self.data_info.loc[index,'imagename'])\n",
    "        # Open image *** JC - I made changes to this part since NEGATIVE_DIR no longer exist ***\n",
    "        img_as_img = Image.open(self.img_path + single_image_name)\n",
    "        # Transform image to tensor\n",
    "        if self.transform is not None:\n",
    "            img_as_img = self.transform(img_as_img)\n",
    "        # Return image and the label\n",
    "        return (img_as_img, single_image_label, raw_label, single_image_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info.index)\n",
    "    \n",
    "    \n",
    "def imshow(inp, norm, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    try:\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "    except:\n",
    "        inp = inp.transpose((1, 2, 0))\n",
    "    mean = norm['mean']\n",
    "    std = norm['std']\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.subplots()\n",
    "    ax.imshow(inp)\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "    \n",
    "def plot_loss(model):\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=2, right = 3, wspace=0.3, bottom = 2, top = 3)\n",
    "    ax = plt.axes()\n",
    "\n",
    "    ax.plot(model.train_loss_curve, label='train')\n",
    "    ax.plot(model.dev_loss_curve, label='dev')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend()\n",
    "    \n",
    "    \n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, gpu_id=None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_loss = 10000.0\n",
    "    best_model = copy.deepcopy(model)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_time = time.time()\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'dev']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  \n",
    "            else:\n",
    "                model.train(False)  \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = torch.zeros(len(IMAGE_CLASSES))\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels, raw_labels, names = data\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    if phase == 'train':\n",
    "                        inputs = Variable(inputs.cuda(), requires_grad=True)\n",
    "                    else:\n",
    "                        inputs = Variable(inputs.cuda(), volatile=True)\n",
    "                    labels = Variable(labels.cuda(), volatile=True)\n",
    "                else:\n",
    "                    if phase == 'train':\n",
    "                        inputs =  Variable(inputs, requires_grad=True)\n",
    "                    else:\n",
    "                        inputs =  Variable(inputs, volatile=True)\n",
    "                    labels = Variable(labels, volatile=True)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if use_gpu:\n",
    "                    predictions = (F.sigmoid(outputs)>0.5).type(torch.cuda.FloatTensor)\n",
    "                else:\n",
    "                    predictions = (F.sigmoid(outputs)>0.5).type(torch.FloatTensor)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(predictions==labels, 0).data.type(torch.FloatTensor)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.module.train_loss_curve.append(epoch_loss)\n",
    "            else:\n",
    "                model.module.dev_loss_curve.append(epoch_loss)\n",
    "\n",
    "            if phase == 'dev' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                print('best loss: ', epoch_loss)\n",
    "\n",
    "            print('{} Loss: {:.4f}\\n Cored: {:.4f} Diffuse: {:.4f} CAA: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc[0], epoch_acc[1], epoch_acc[2]))\n",
    "\n",
    "        epoch_end = time.time() - epoch_time\n",
    "        print('train, Epoch time {:.0f}m {:.0f}s'.format(\n",
    "                epoch_end // 60, epoch_end % 60))\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def dev_model(model, criterion, phase='dev'):\n",
    "    phase = phase\n",
    "    since = time.time()\n",
    "    \n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=num_workers)\n",
    "              for x in [phase]}\n",
    "\n",
    "    model.train(False) \n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = torch.zeros(len(IMAGE_CLASSES))\n",
    "    running_preds = torch.Tensor(0)          # confidence score\n",
    "    running_predictions = torch.Tensor(0)    # classification prediction\n",
    "    running_labels = torch.Tensor(0)\n",
    "    running_raw_labels = torch.Tensor(0)\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloaders[phase]:\n",
    "        # get the inputs\n",
    "        inputs, labels, raw_labels, names = data\n",
    "        running_labels = torch.cat([running_labels, labels])\n",
    "        running_raw_labels = torch.cat([running_raw_labels, raw_labels])\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        preds = F.sigmoid(outputs) #posibility for each class\n",
    "        if use_gpu:\n",
    "            predictions = (preds>0.5).type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            predictions = (preds>0.5).type(torch.FloatTensor)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        preds = preds.data.cpu()\n",
    "        predictions = predictions.data.cpu()\n",
    "        labels = labels.data.cpu()\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.data[0]\n",
    "        running_corrects += torch.sum(predictions==labels, 0).type(torch.FloatTensor)\n",
    "        running_preds = torch.cat([running_preds, preds])\n",
    "        running_predictions = torch.cat([running_predictions, predictions])\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "    epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "    print('{} Loss: {:.4f}\\n Cored: {:.4f} Diffuse: {:.4f} CAA: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc[0], epoch_acc[1], epoch_acc[2]))\n",
    "\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Prediction complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return epoch_acc, running_preds, running_predictions, running_labels\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, fc_nodes=512, num_classes=3, dropout=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.drop = 0.2\n",
    "     \n",
    "        self.features = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1),\n",
    "                                      nn.Dropout2d(self.drop),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                      \n",
    "                                      nn.Conv2d(64, 64, 3, padding=1),\n",
    "                                      nn.Dropout2d(self.drop),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                      \n",
    "                                      nn.Conv2d(64, 128, 3, padding=1),\n",
    "                                      nn.Dropout2d(self.drop),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                      \n",
    "                                      nn.Conv2d(128, 256, 3, padding=1),\n",
    "                                      nn.Dropout2d(self.drop),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                      \n",
    "                                      nn.Conv2d(256, 256, 3, padding=1),\n",
    "                                      nn.Dropout2d(self.drop),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                      \n",
    "                                      nn.Conv2d(256, 512, 3, padding=1),\n",
    "                                      nn.Dropout2d(self.drop),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.MaxPool2d(kernel_size=2, stride=2),)\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Linear(512 * 4 * 4, fc_nodes),\n",
    "                                        nn.ReLU(True),\n",
    "                                        nn.Dropout(p=dropout),\n",
    "                                        nn.Linear(fc_nodes, 100),\n",
    "                                        nn.ReLU(True),\n",
    "                                        nn.Dropout(p=dropout),\n",
    "                                        nn.Linear(100, num_classes))\n",
    "        \n",
    "        self.train_loss_curve = []\n",
    "        self.dev_loss_curve = []\n",
    "\n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "# create save directory\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# load color normalization info\n",
    "norm = np.load('../modules/normalization.npy').item()\n",
    "\n",
    "# create data transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(180),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.2,saturation=0.2, hue=0.02),\n",
    "        transforms.RandomAffine(0, translate=(0.05,0.05), scale=(0.9,1.1), shear=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm['mean'], norm['std'])\n",
    "    ]),\n",
    "    'dev': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm['mean'], norm['std'])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: MultilabelDataset(CSV_PATH[x], DATA_DIR, data_transforms[x])\n",
    "              for x in ['train', 'dev']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=NUM_WORKERS)\n",
    "              for x in ['dev', 'train']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'dev']}\n",
    "print(\"{} training images, {} validation images\".format(dataset_sizes[\"train\"], dataset_sizes[\"dev\"]))\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"GPU found, will use it during training\")\n",
    "else:\n",
    "    print(\"No GPU found, training on CPU\")\n",
    "\n",
    "# get a batch of training data, make into grid from batch size and show\n",
    "inputs, labels, raw_labels, names = next(iter(dataloaders['train']))\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out, norm)\n",
    "\n",
    "weight = torch.FloatTensor([1,1,1])\n",
    "model = Net()\n",
    "\n",
    "if use_gpu:\n",
    "    weight = weight.cuda()\n",
    "    # ||||||||||||||||||| if you have multiple GPUs - then set device_ids to [0, 1, 2, ...] ||||||||||||||| #\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.MultiLabelSoftMarginLoss(weight=weight, size_average=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00008, weight_decay=0.008)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.4)\n",
    "\n",
    "# train the model\n",
    "best_model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=60)\n",
    "\n",
    "# save the model\n",
    "if os.path.isfile(oj(SAVE_DIR, SAVE_NAME)):\n",
    "    print('File {} already exists - not saving new model'.format(oj(SAVE_DIR, SAVE_NAME)))\n",
    "else:\n",
    "    torch.save(best_model, os.path.join(SAVE_DIR, SAVE_NAME))\n",
    "\n",
    "# plot the loss during training\n",
    "plot_loss(model.module)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
