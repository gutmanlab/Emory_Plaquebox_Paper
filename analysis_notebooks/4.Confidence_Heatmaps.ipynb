{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Emory Confidence Heatmaps\n",
    "\n",
    "Generate a confidence heatmap image, where each channel corresponds to a pathology feature (cored, diffuse, CAA). The main function runs this for a single input, which is the directory with norm tiles for a WSI. These tiles are used to generate three confidence heatmap for that WSI (one for each class of pathology: cored, diffuse, CAA).\n",
    "\n",
    "NOTE - this notebook is the longest running notebook of the project. Each WSI can take 2-4 hours to create the heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys, os, glob\n",
    "import torch\n",
    "torch.manual_seed(123456789)\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from os.path import join as oj\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>PyTorch Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch classes for loading model\n",
    "class HeatmapDataset(Dataset):\n",
    "    def __init__(self, tile_dir, row, col, normalize=None, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_dir (string): path to the folder where tiles are\n",
    "            row (int): row index of the tile being operated\n",
    "            col (int): column index of the tile being operated\n",
    "            normalize is a color norm transform\n",
    "            stride: stride of sliding (low strides lead to long computational times)\n",
    "        \"\"\"\n",
    "        # tile_size and img_size should not have been changed in the pipeline\n",
    "        self.tile_size = 256\n",
    "        self.img_size = 1536\n",
    "        self.stride = stride\n",
    "        padding = 128\n",
    "        large_img = torch.ones(3, 3*self.img_size, 3*self.img_size)\n",
    "        \n",
    "        for i in [-1,0,1]:\n",
    "            for j in [-1,0,1]:\n",
    "                img_path = tile_dir+'/'+str(row+i)+'/'+str(col+j)+'.jpg'\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img = transforms.ToTensor()(img) \n",
    "                except:\n",
    "                    img = torch.ones(3,self.img_size, self.img_size)\n",
    "                \n",
    "                large_img[:, (i+1)*self.img_size:(i+2)*self.img_size,\n",
    "                          (j+1)*self.img_size:(j+2)*self.img_size] = img\n",
    "        \n",
    "        if normalize is not None:\n",
    "            large_img = normalize(large_img)\n",
    "        \n",
    "        self.padding_img = large_img[:,self.img_size-padding:2*self.img_size+padding,\n",
    "                                     self.img_size-padding:2*self.img_size+padding]\n",
    "        self.len = (self.img_size//self.stride)**2\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = (index*self.stride // self.img_size)*self.stride\n",
    "        col = (index*self.stride % self.img_size)\n",
    "\n",
    "        img = self.padding_img[:, row:row+self.tile_size, col:col+self.tile_size]        \n",
    "    \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, fc_nodes=512, num_classes=3, dropout=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_conf_heatmap(model, tile_dir, save_path=None, **kwargs):\n",
    "# img_size, stride, norm_transform, batch_size, num_workers, use_gpu):\n",
    "    \"\"\"Generate confidence heatmap using a trained model and a tiled image directory.\n",
    "    \n",
    "    :param model : PyTorch model\n",
    "        trained CNN model\n",
    "    :param tile_dir : str\n",
    "        the directory containing the tiled images\n",
    "    :param save_path : str (default: None)\n",
    "        location to save confidence heatmap (with filename, no extension). If None then it will not be saved\n",
    "        but still returned.\n",
    "    :param kwargs : dict\n",
    "        look below for kwargs params, must be passed\n",
    "    \n",
    "    :return final_output : ndarray\n",
    "        confidence heatmap for the image, each channel is a heatmap for a class of pathologies (cored, diffuse,\n",
    "        CAA)    \n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    \n",
    "    # get metadata of tiled directory (col array, row array, num of col and rows) for looping in sliding\n",
    "    # window approach\n",
    "    for target in sorted(os.listdir(tile_dir)):\n",
    "        d = os.path.join(tile_dir, target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                # only grabs the paths to .jpg\n",
    "                if fname.endswith('.jpg'):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    imgs.append(path)\n",
    "    # imgs contains the list of file/tile images\n",
    "\n",
    "    # to match imgs get the row and column lists - this helps know where to put the output of each tile in \n",
    "    # the overall image\n",
    "    rows = [int(image.split('/')[-2]) for image in imgs]\n",
    "    row_nums = max(rows) + 1\n",
    "    cols = [int(image.split('/')[-1].split('.')[0]) for image in imgs]\n",
    "    col_nums = max(cols) +1  \n",
    "    heatmap_res = kwargs['img_size'] // kwargs['stride']\n",
    "    final_output = np.zeros((3, heatmap_res*row_nums, heatmap_res*col_nums))\n",
    "\n",
    "    # loop through each row and col\n",
    "    for row in tqdm_notebook(range(row_nums)):\n",
    "        for col in range(col_nums):\n",
    "            # load the data for a row, col pair\n",
    "            image_datasets = HeatmapDataset(tile_dir, row, col, normalize=kwargs['normalize'], \n",
    "                                            stride=kwargs['stride'])\n",
    "            dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=kwargs['batch_size'],\n",
    "                                                     shuffle=False, num_workers=kwargs['num_workers'])\n",
    "\n",
    "            # predict on the image\n",
    "            running_preds = torch.Tensor(0)\n",
    "            for data in dataloader:\n",
    "                # get the inputs\n",
    "                inputs = data\n",
    "                # wrap them in Variable\n",
    "                if kwargs['use_gpu']:\n",
    "                    inputs = Variable(inputs.cuda(), volatile=True)\n",
    "                \n",
    "                    # forward\n",
    "                    outputs = model(inputs)\n",
    "                    preds = F.sigmoid(outputs)  # posibility for each class\n",
    "                    preds = preds.data.cpu()\n",
    "                    running_preds = torch.cat([running_preds, preds])\n",
    "\n",
    "            # add image to output\n",
    "            cored = np.asarray(running_preds[:,0]).reshape(\n",
    "                kwargs['img_size']//kwargs['stride'],kwargs['img_size']//kwargs['stride'])\n",
    "            diffuse = np.asarray(running_preds[:,1]).reshape(\n",
    "                kwargs['img_size']//kwargs['stride'],kwargs['img_size']//kwargs['stride'])\n",
    "            caa = np.asarray(running_preds[:,2]).reshape(\n",
    "                kwargs['img_size']//kwargs['stride'],kwargs['img_size']//kwargs['stride'])\n",
    "\n",
    "            final_output[0, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = cored\n",
    "            final_output[1, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = diffuse\n",
    "            final_output[2, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = caa\n",
    "\n",
    "    if save_path is not None:      \n",
    "        np.save(save_path, final_output)\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_stats_path = '../modules/normalization.npy'  # used for color norm transform\n",
    "img_size = 1536\n",
    "stride = 16  # 16 is used in paper\n",
    "batch_size = 64  # vary depending on computer running code\n",
    "num_workers = 16  # vary depending on computer running code\n",
    "\n",
    "norm = np.load(norm_stats_path, allow_pickle=True).item()\n",
    "normalize = transforms.Normalize(norm[\"mean\"], norm[\"std\"])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# GPU check\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "kwargs = {\n",
    "    'img_size': img_size, 'stride': stride, 'batch_size': batch_size, 'num_workers': num_workers, \n",
    "    'normalize': normalize, 'use_gpu': use_gpu\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Run</center>\n",
    "This is long running process per image, can take 2-4 hours depending on the original file size, GPU used, and system set-up (i.r. RAM available). \n",
    "\n",
    "To run select the norm tile dir to work on, such as norm_tiles_dataset_emory. Select the appropriate location to save the heatmap to, note that it will NOT override any heatmap already present there of the same name. It will skip this cases. Lastly, choose the model to use for creating the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"***Parameters***\"\"\"\n",
    "# choose a directory of norm tiles to generate confidence heatmaps for\n",
    "DIR = '/mnt/Data/norm_tiles/norm_tiles_dataset_3/'\n",
    "SAVE_DIR = '/mnt/Data/outputs/heatmaps_tang/'\n",
    "# if batch is none it will run on all norm tile dirs\n",
    "# otherwise the normtile dirs will be sorted alphabetically and will be run only\n",
    "# on the range of indices provided\n",
    "batch = (0, None)  # (start index, end index excluded)\n",
    "\n",
    "model_path = '../models/CNN_model_parameters.pkl'\n",
    "# model_path = '../models/CNN_fresh_model_parameters.pkl'\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# instatiate the model\n",
    "model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "# modify for gpu usage\n",
    "if use_gpu:\n",
    "    print('using GPU')\n",
    "    model = model.module.cuda()\n",
    "else:\n",
    "    model = model.module\n",
    "    \n",
    "_ = model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "\n",
    "\"\"\"***main code***\"\"\"\n",
    "pprint(kwargs)\n",
    "print()\n",
    "\n",
    "# list the norm dirs\n",
    "filenames = sorted(glob.glob(DIR + '*'))\n",
    "\n",
    "filenames = [filename.split('/')[-1] for filename in filenames]\n",
    "    \n",
    "if batch is None:\n",
    "    print('Running on all norm dirs')\n",
    "    batch = (0, len(filenames))\n",
    "else:\n",
    "    print('Running on indices {} to {}'.format(batch[0], batch[1] - 1))\n",
    "    \n",
    "    \n",
    "indices = list(range(batch[0], batch[1]))\n",
    "n = len(indices)\n",
    "for i in indices:\n",
    "    filename = filenames[i]\n",
    "    print('running index {}'.format(i))\n",
    "    # does not rerun already existing heatmaps\n",
    "    save_path = oj(SAVE_DIR, filename+\".npy\")\n",
    "    if not os.path.isfile(save_path):\n",
    "        print(\"\\tanalyzing {}\".format(filename))\n",
    "        tile_dir = oj(DIR, '{}/0/'.format(filename))\n",
    "        _ = sliding_conf_heatmap(model, tile_dir, save_path=save_path, **kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
